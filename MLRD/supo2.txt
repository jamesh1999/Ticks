Emissions just depends on current state (irrellevant of order)

Observable MM could be used to determine whether words are in english -> sequence of letters

2.2
Store cumulative probabilities
Generate (uniform dist) [0,1]

2.3
Can't make transition "the" -> END

3.1
Count = 0
=> Impossible transition, not seen
Smoothing resolves data sparsity (many emission states, emission mat good for smoothing)

4.1




Laws of lang. => More data => More unique words => count=0 for some emissions

Pronouns are a "closed class" (languages less likely to add pronouns) => Np smoothing on this class

O(tN^k+1)


   s    i    o    f
s  0   0.5  0.5   0
i  0   0.5  1/3  1/6
o  0   3/8  0.5  1/8
f  0    0    0    0

  today may bakes a   nice cake peter and mary like sue
i   0   1/6  1/3  0    0    0    1/6  0   1/6   0    1/6
o   1/8 1/8  1/8 1/8  1/8  1/8   0     1/8 0    1/8  0


0.5*1/6*1/3*1/8*1/8=4.34e-4
0.5*1/8*3/8*1/3*1/6=1.30e-3

May | i = 0
=> c.i is p(0)